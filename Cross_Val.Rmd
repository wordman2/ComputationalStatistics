---
title: "Cross_Validation"
author: "Jonas Wortmann"
date: "2023-04-24"
output: 
  html_document:
    toc: true
---

### Lineare Regression

```{r}
load("data/Donald.RData")

Donald_1$Minderheit <- factor(Donald_1$Minderheit)
Donald_1$Geschlecht <- factor(Donald_1$Geschlecht, labels=c("w", "m"))

model <- lm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=Donald_1)
summary(model)
```

Je älter desto höher ist die Zustimmung für Trump. Männliche Wahlberechtigte stimmen eher für Trump. Personen, die keiner Minderheit angehören stimmen eher für Trump als Personen, die einer Minderheit angehören. Fremdenfeindliche Wähler stimmen eher für Trump als nicht-fremdenfeindliche. Je niedriger der IQ, desto höher ist die Zustimmung für Trump.

### Split in Test- und Trainingsdaten und Vergleich der Verteilungen der Variablen

```{r, warning=FALSE, message=FALSE, echo = FALSE}
require(ggplot2)
require(gridExtra)

set.seed(1)
plots <- list()
mses <- c()
for (i in 1:3){
  
  train_test_split <- sample(c(rep(0, 100), rep(1, 50)))
  train <- Donald_1[train_test_split == 0,]
  train$group <- "TRAIN"
  test <- Donald_1[train_test_split == 1,]
  test$group <- "TEST"

  plot_alter <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=Alter, fill=group, col=group),  alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=Alter, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_geschlecht <- ggplot() + 
    geom_bar(data=train, 
             mapping=aes(x=Geschlecht, y=..count../sum(..count..), fill=group, col=group), 
             alpha=0.5,
             ) +
    geom_bar(data=test, 
             mapping=aes(x=Geschlecht, y=..count../sum(..count..), fill=group, col=group), 
             alpha=0.5)

  plot_minderheit <- ggplot() +
    geom_bar(data=train, mapping=aes(x=Minderheit, y=..count../sum(..count..), fill=group, col=group), alpha=0.5) +
    geom_bar(data=test, mapping=aes(x=Minderheit, y=..count../sum(..count..), fill=group, col=group), alpha=0.5)
    
  if(i == 3) {
    plot_minderheit <- plot_minderheit + guides(fill=guide_legend(), color=guide_legend())
    plot_geschlecht <- plot_geschlecht + guides(fill=guide_legend(), color=guide_legend())
  }else {
    plot_minderheit <- plot_minderheit + guides(fill=FALSE, color=FALSE)
    plot_geschlecht <- plot_geschlecht + guides(fill=FALSE, color=FALSE)
    }
  
  plot_fremdenfeindlich <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=Fremdenfeindlich, fill=group, col=group), alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=Fremdenfeindlich, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_iq <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=IQ, fill=group, col=group), alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=IQ, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_trump_zustimmung <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=Trump, fill=group, col=group), alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=Trump, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
   
  plots <- append(plots, list(plot_alter, plot_geschlecht, plot_minderheit, plot_fremdenfeindlich, plot_iq, plot_trump_zustimmung))
  
  model <- lm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=train)
  predictions <- predict(model, test)
  mse <- mean((test$Trump - predictions)**2)
  mses <- c(mses, mse)
  
}
y_labs <- c("Alter", "%", "%", "Fremdenfeindlichkeit", "IQ", "Trump Zustimmung (%)")
num_plots <- length(y_labs)

create_grid_plot <- function(variable, choices) {
  i <- which(variable == choices) 
  return(grid.arrange(plots[[i]] + ggtitle("Split #1") + ylab(y_labs[i]),
                                     plots[[i+num_plots]] + ylab("") + ggtitle("Split #2"),
                                     plots[[i+num_plots*2]] + ylab("") + ggtitle("Split #3"),
                                     nrow=1))}

choices <- c("Alter", "Geschlecht", "Minderheit", "Fremdenfeindlichkeit", "IQ", "Trump_Zustimmung")

```
```{r}
selectInput("data", "Select a variable", choices)
```

```{r echo=FALSE}
renderPlot({
  create_grid_plot(input$data, choices)
})

```

```{r}
# plot MSEs
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)")
```

Im Alter unterscheiden sich die Splits nicht stark zwischen Trainings- und Testdatensatz. In Split #3 sind etwas ältere Personen im Training als im Test.
Im Testdatensatz in Split #2 und #3 befinden sich mehr Frauen als im Trainingsdatensatz. In Split #1 befinden sich mehr Frauen im Trainingsdatensatz als Männer.
Die Verteilung der Minderheiten ist in jedem Split in etwa ähnlich.
In Split #1 umd #3 befinden sich mehr fremdenfeindlichere Personen im Test- als im Trainingsdatensatz, während in Split #2 der gegenteilige Effekt etwas weniger ausgeprägt ist.
In Split #3 ist der IQ im Trainingsdatensatz höher als im Test. Bei den anderen Splits sind sie in etwa identisch.
In allen Splits befinden sich im Testdatensatz systematisch mehr Trump Anhänger als im Trainingsdatensatz, in #3 ist der Effekt am deutlichsten.
Nach den MSEs zu urteilen, sind die lineare Regressionsmodelle die mit die Trainingsdaten von Split #1 und #3 trainiert wurden, machen präzisere Vorhersagen als das Modell von Split #2. Eine Ursache könnte die Variable Fremdenfeindlichkeit sein.

### Leave-One-Out Cross Validation

```{r}

ses <- c()
for(i in 1:nrow(Donald_1)){
  data <- Donald_1[-i,]
  model <- lm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=data)
  prediction <- predict(model, Donald_1[i,])
  squared_error <- (Donald_1[i,]$Trump - prediction)**2
  ses <- c(ses, squared_error)
}
mse_loo <- mean(ses)
mses <- c(mses,mse_loo)
mses <- round(mses, 2)
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3", "LOO-CV"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)") +
  geom_text(aes(label=MSE), vjust=-0.5)
```

Der MSE von Split #1 und #3 ist geringer als der von der LOO-CV. Der MSE von allen CV-Splits hängt stark von den Samples im Training- und Testdatensatz ab. Ist der Split günstig, d. h. lässt sich der Testdatensatz durch den Trainingsdatensatz gut vorhersagen, führt das zu einem geringen MSE. Aber nur weil der Testdatensatz des Splits gut vorhersagbar ist, heißt das nicht, dass es auf weitere ungesehene Daten zutrifft. Die LOO-Methode passt das Modell an allen Daten an, darum ist das Ergebnis konstant.

```{r}
# Leave one Out mit der glm Funktion
library(boot)
linear.reg_model <- glm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=Donald_1)
cv_glm <- cv.glm(Donald_1, linear.reg_model)
mse_loo_glm <- round(cv_glm$delta[1], 2)
mses <- c(mses,mse_loo_glm)
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3", "LOO-CV", "LOO-CV glm"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)") +
  geom_text(aes(label=MSE), vjust=-0.5)
```

Das Ergebnis mit cv.glm ist mit der Loop-Durchführung identisch.

### k-fache Cross Validation

```{r}
for(K in c(5,10)){
  errors <- c()
  for(i in 1:10){
    cv_glm <- cv.glm(Donald_1, linear.reg_model, K=K)
    errors <- c(errors,round(cv_glm$delta[1]))
  }
  mse <- mean(errors)
  mses <- c(mses, mse)
}
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3", "LOO-CV", "LOO-CV glm",
                                       "k=5 CV", "k=10 CV"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)") +
  geom_text(aes(label=MSE), vjust=-0.5)
```

Die MSEs der k-fachen Cross Validierung zeigt mit k=5 und k=10 keine großen Differenzen auf. Auch zur LOO-CV ist keine großer Unterschied zu sehen.
