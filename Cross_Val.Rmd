---
title: "Cross_Validation"
author: "Jonas Wortmann"
date: "2023-04-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Cross Validation

### Lineare Regression

```{r}
load("data/Donald.RData")

Donald_1$Minderheit <- factor(Donald_1$Minderheit)
Donald_1$Geschlecht <- factor(Donald_1$Geschlecht, labels=c("w", "m"))

model <- lm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=Donald_1)
summary(model)
```

Je älter desto höher ist die Zustimmung für Trump. Männliche Wahlberechtigte stimmen eher für Trump. Personen, die keiner Minderheit angehören stimmen eher für Trump als Personen, die einer Minderheit angehören. Fremdenfeindliche Wähler stimmen eher für Trump als nicht-fremdenfeindliche. Je niedriger der IQ, desto höher ist die Zustimmung für Trump.

### A1 Split in Test- und Trainingsdaten und Vergleich der Verteilungen der Variablen

```{r}
require(ggplot2)
require(gridExtra)

set.seed(1)
plots <- list()
mses <- c()
for (i in 1:3){
  
  train_test_split <- sample(c(rep(0, 100), rep(1, 50)))
  train <- Donald_1[train_test_split == 0,]
  train$group <- "TRAIN"
  test <- Donald_1[train_test_split == 1,]
  test$group <- "TEST"

  plot_alter <- ggplot() + 
    geom_boxplot(data=train, mapping=aes(x=group, y=Alter, fill=group, col=group),  alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=Alter, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_geschlecht <- ggplot() + 
    geom_bar(data=train, 
             mapping=aes(x=Geschlecht, y=..count../sum(..count..), fill=group, col=group), 
             alpha=0.5,
             ) +
    geom_bar(data=test, 
             mapping=aes(x=Geschlecht, y=..count../sum(..count..), fill=group, col=group), 
             alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_minderheit <- ggplot() +
    geom_bar(data=train, mapping=aes(x=Minderheit, y=..count../sum(..count..), fill=group, col=group), alpha=0.5) +
    geom_bar(data=test, mapping=aes(x=Minderheit, y=..count../sum(..count..), fill=group, col=group), alpha=0.5)
    
  if(i == 3) plot_minderheit <- plot_minderheit + guides(fill=guide_legend(), color=guide_legend())
  else plot_minderheit <- plot_minderheit + guides(fill=FALSE, color=FALSE)
  
  plot_fremdenfeindlich <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=Fremdenfeindlich, fill=group, col=group), alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=Fremdenfeindlich, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_iq <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=IQ, fill=group, col=group), alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=IQ, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
  
  plot_trump_zustimmung <- ggplot() +
    geom_boxplot(data=train, mapping=aes(x=group, y=Trump, fill=group, col=group), alpha=0.5) +
    geom_boxplot(data=test, mapping=aes(x=group, y=Trump, fill=group, col=group), alpha=0.5) +
    guides(fill=FALSE, color=FALSE)
   
  plots <- append(plots, list(plot_alter, plot_geschlecht, plot_minderheit, plot_fremdenfeindlich, plot_iq, plot_trump_zustimmung))
  
  model <- lm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=train)
  predictions <- predict(model, test)
  mse <- mean((test$Trump - predictions)**2)
  mses <- c(mses, mse)
  
}
y_labs <- c("Alter", "%", "%", "Fremdenfeindlichkeit", "IQ", "Trump Zustimmung (%)")
num_plots <- 6

# plot distributions
for (i in 1:num_plots) {grid.arrange(plots[[i]] + ggtitle("Split #1") + ylab(y_labs[i]),
                                     plots[[i+num_plots]] + ylab("") + ggtitle("Split #2"),
                                     plots[[i+num_plots*2]] + ylab("") + ggtitle("Split #3"), 
                                     nrow=1)}

# plot MSEs
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)")
```

Das Alter im ersten Split ist in den Testdaten höher, als in den Trainingsdaten. Im dritten Split sind in den Trainingsdaten weniger Daten von Personen enthalten, die einer Minderheit angehören. Die Verteilung der Trump Zustimmung ist vor allem in zweiten Split besonders unterschiedlich: In den Testdaten befinden sich mehr Trump-Anhänger als in den Trainingsdaten. Die lineare Regressionsmodelle die mit die Trainingsdaten von Split 2 und 3 trainiert wurden, machen präzisere Vorhersagen als das Modell von Split 1.

### A 2 Leave-One-Out Cross Validation

```{r}

ses <- c()
for(i in 1:nrow(Donald_1)){
  data <- Donald_1[-i,]
  model <- lm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=data)
  prediction <- predict(model, Donald_1[i,])
  squared_error <- (Donald_1[i,]$Trump - prediction)**2
  ses <- c(ses, squared_error)
}
mse_loo <- mean(ses)
mses <- c(mses,mse_loo)
mses <- round(mses, 2)
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3", "LOO-CV"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)") +
  geom_text(aes(label=MSE), vjust=-0.5)
```

Der MSE von Split 2 und 3 ist geringer als der von der LOO-CV. Der MSE von Split 2 und 3 hängt stark von den Samples im Training- und Testdatensatz ab. Ist der Split günstig, d. h. lässt sich der Testdatensatz durch den Trainingsdatensatz gut vorhersagen, führt das zu einem geringen MSE. Aber nur weil der Testdatensatz des Splits gut vorhersagbar ist, heißt das nicht, dass es auf weitere ungesehene Daten zutrifft. Die LOO-Methode passt das Modell an allen Daten an und das Ergebnis ist darum konstant.

```{r}
# Leave one Out mit der glm Funktion
library(boot)
linear.reg_model <- glm(Trump ~ Alter+Geschlecht+Minderheit+Fremdenfeindlich+IQ, data=Donald_1)
cv_glm <- cv.glm(Donald_1, linear.reg_model)
mse_loo_glm <- round(cv_glm$delta[1], 2)
mses <- c(mses,mse_loo_glm)
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3", "LOO-CV", "LOO-CV glm"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)") +
  geom_text(aes(label=MSE), vjust=-0.5)
```

Das Ergebnis mit cv.glm ist mit der Loop-Durchführung identisch.

### k-fache Cross Validation

```{r}
for(K in c(5,10)){
  errors <- c()
  for(i in 1:10){
    cv_glm <- cv.glm(Donald_1, linear.reg_model, K=K)
    errors <- c(errors,round(cv_glm$delta[1]))
  }
  mse <- mean(errors)
  mses <- c(mses, mse)
}
ggplot(data.frame(MSE=mses), aes(x = c("Split #1", "Split #2", "Split #3", "LOO-CV", "LOO-CV glm",
                                       "k=5 CV", "k=10 CV"), y = MSE)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("MSE") +
  ggtitle("Mean Squared Error (MSE)") +
  geom_text(aes(label=MSE), vjust=-0.5)
```
Die MSEs der k-fachen Cross Validierung zeigt mit k=5 und k=10 keine großen Differenzen auf. Auch zur LOO-CV ist keine großer Unterschied zu sehen. 
